<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Seqam Lab</title>
  <!-- Link to CSS -->
  <link rel="stylesheet" href="style.css">
  <script>
    (function(d) {
      var config = {
        kitId: 'oed5xho',
        scriptTimeout: 3000,
        async: true
      },
      h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
    })(document);
  </script>
  <link rel="icon" type="image/png" href="data/images/icons/web.png">
</head>

<script src="script.js"></script>
<body>



  <!-- ******************************************************* -->
  <!-- ************* Header Section ************************** -->
  <!-- ******************************************************* -->
  <div class="navbar-container">
    <!-- Half-image that the navbar will overlay -->
    <img src="data/images/header.jpg" alt="Header Image" class="header-image">

    <!-- Title Section -->
    <div class="title-overlay">
      SEQAM LAB
    </div>

    <!-- Navigation Bar -->
    <div class="navbar">
        <!-- Logo Section -->
        <div class="navbar-logo">
          <img src="data/images/logo.png" alt="SequentLab Logo" class="logo-image">
        </div>

        <div class="navbar-divider"></div>

        <!-- Lab Title -->
        <div class="navbar-title">
          Sequence Analysis ands Modeling Lab
        </div>

        <!-- The Actual Navi Bar -->
        <div class="navbar-box">
          <!-- Tags (Clickable Menu Items) -->
          <a href="#home" class="navbar-tag">Home</a>
          <a href="#people" class="navbar-tag">People</a>
          <a href="#research" class="navbar-tag">Slected Publications</a>
          <a href="#contact" class="navbar-tag">Contact</a>
        </div>
    </div>
  </div>



  <!-- ******************************************************* -->
  <!-- ************* About Us Section ************************ -->
  <!-- ******************************************************* -->
  <div id="about" class="about-us-container">
    <div class="about-us-content">
      <div class="about-us-text">
        <h2>About Us</h2>
        <p>
          SEQAM – Sequence Analysis and Modeling Lab conducts research in computational modeling methods for analysis of multimodal and multivariate data, with particular focus on sequential data, such as time-series (video, audio, motion sensors), 
          biomedical data (imaging, genomic, proteomic, etc.)   
          We develop mathematical and statistical models and the accompanying algorithms that can rapidly process large and heterogeneous datasets and reveal the underlying, latent factors affecting the data.

          SEQAM – Sequence Analysis and Modeling Lab conducts research in computational modeling methods for analysis of multimodal and multivariate data, with particular focus on sequential data, such as time-series (video, audio, motion sensors), 
          biomedical data (imaging, genomic, proteomic, etc.)   
          We develop mathematical and statistical models and the accompanying algorithms that can rapidly process large and heterogeneous datasets and reveal the underlying, latent factors affecting the data.
        </p>
      </div>
      <div class="professor-image-container">
        <img src="data/images/people/vlad.jpg" alt="Professor" class="professor-image">
        <div class="social-icons">
          <!-- Email Button -->
          <a href="mailto:vladimir@cs.rutgers.edu" class="social-icon">
            <img src="data/images/icons/email.png" alt="Email">
          </a>
          <!-- LinkedIn Button -->
          <a href="https://www.linkedin.com/in/vladimir-pavlovic-a5528412/" class="social-icon" target="_blank">
            <img src="data/images/icons/linkedin.png" alt="LinkedIn">
          </a>
          <!-- Google Scholar Button -->
          <a href="https://scholar.google.com/citations?user=8MQT8skAAAAJ" class="social-icon" target="_blank">
            <img src="data/images/icons/googlescholar.png" alt="Google Scholar">
          </a>
        </div>
      </div>
    </div>
  </div>



  <!-- ******************************************************* -->
  <!-- ************* Lab Members Section ********************* -->
  <!-- ******************************************************* -->
  <div id="people" class="section-bar-container">
    <img src="data/images/people_header.jpg" alt="Section Image" class="section-header-image">
    <div class="section_title-overlay">
      Lab Members
    </div>
  </div>

  <div class="people-container">
    
    <!-- ******** Xinxi ********** -->
    <div class="people-item">
      <img src="data/images/people/xinxi.jpeg" alt="Person Xinxi" class="person-image">
      <p class="person-name">
        <a href="https://scholar.google.com/citations?user=08KI_O0AAAAJ&hl=en" class="profile-link" target="_blank">Xinxi Zhang</a>
      </p>
    </div>


      <!-- ******** Tony ********** -->
      <div class="people-item">
        <img src="data/images/people/tony.jpg" alt="Person Tony" class="person-image">
        <p class="person-name">
          <a href="https://scholar.google.com/citations?user=qPmO1EIAAAAJ&hl=en" class="profile-link" target="_blank">Qingze (Tony) Liu</a>
        </p>
      </div>

      <!-- ******** Alen ********** -->
      <div class="people-item">
        <img src="data/images/people/alen.jpg" alt="Person Alen" class="person-image">
        <p class="person-name">
          Alen Mrdovic
        </p>
      </div>

      <!-- ******** Kalliopi ********** -->
      <div class="people-item">
        <img src="data/images/people/kalliopi.jpg" alt="Person Kalliopi" class="person-image">
        <p class="person-name">
          <a href="https://sites.google.com/view/kalliopi-basioti/" class="profile-link" target="_blank">Kalliopi Basioti</a>
        </p>
      </div>
      
    </div>



  <!-- ******************************************************* -->
  <!-- ************* Pub Section ***************************** -->
  <!-- ******************************************************* -->
  <div id="research" class="section-bar-container">
    <img src="data/images/pub_header.jpg" alt="Section Image" class="section-header-image">
    <div class="section_title-overlay">
      Selected Publications
    </div>
  </div>


  <!-- ********************************* -->
  <!-- **** Publication 1 GenVP ******** -->
  <!-- ********************************* -->
  <div class="pub-container">
    <img src="data/images/pubs/genvp.png" alt="Sample Image" class="pub-image" width="200">
    
    <h1>
        <a href="https://openreview.net/pdf?id=Pd7IOswRUZ" target="_blank" rel="noopener noreferrer">
            GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs
        </a>
    </h1>
    
    <h2>Kalliopi Basioti, Pritish Sahu, Tony Qingze Liu, Zihao Xu, Hao Wang, Vladimir Pavlovic</h2>
    
    <!-- TL;DR Version -->
    <p class="abstract short-abstract">
        <hl>TL;DR:</hl> GenVP is a framework that generates visual puzzles using contrastive hierarchical VAEs, surpassing existing models in accuracy and generalization.
        <span class="toggle-abstract show-full">(Show Full Abstract)</span>
    </p>

    <!-- Full Abstract (Initially Hidden) -->
    <p class="abstract full-abstract" style="display: none;">
        Raven’s Progressive Matrices (RPMs) is an established benchmark to examine the ability to perform high-level abstract visual reasoning (AVR). 
        Despite the current success of algorithms that solve this task, humans can generalize beyond a given puzzle and create new puzzles given a set of rules, 
        whereas machines remain locked in solving a fixed puzzle from a curated choice list. 
        <hl>We propose Generative Visual Puzzles (GenVP), a framework to model the entire RPM generation process, a substantially more challenging task. 
        Our model’s capability spans from generating multiple solutions for one specific problem prompt to creating complete new puzzles out of the desired set of rules. </hl>
        Experiments on five different datasets indicate that GenVP achieves state-of-the-art (SOTA) performance both in puzzle-solving accuracy and out-of-distribution (OOD) generalization in 22 out of 24 OOD scenarios. 
        Further, compared to SOTA generative approaches, which struggle to solve RPMs when the feasible solution space increases, GenVP efficiently generalizes to these challenging scenarios. 
        Moreover, our model demonstrates the ability to produce a wide range of complete RPMs given a set of abstract rules by effectively capturing the relationships between abstract rules and visual object properties.
        <span class="toggle-abstract show-tldr" style="display: none;">(Show TL;DR)</span>
    </p>

    <div class="pub-keywords">
        <span class="pub-keyword">Visual Puzzles</span>
        <span class="pub-keyword">Probabilistic Graphical Models</span>
        <span class="pub-keyword">ICLR 2025</span>
    </div>
  </div>

  
  <!-- ********************************* -->
  <!-- **** Publication 2 SODA ********* -->
  <!-- ********************************* -->
  <div class="pub-container">
    <img src="data/images/pubs/soda.png" alt="Sample Image" class="pub-image" width="200">
    
    <h1>
        <a href="https://arxiv.org/pdf/2405.21050" target="_blank" rel="noopener noreferrer">
          SODA: Spectrum-Aware Parameter-Efficient Fine-Tuning for Diffusion Models
        </a>
    </h1>
    
    <h2>Xinxi Zhang*, Song Wen*, Ligong Han*†, Felix Juefei-Xu, Akash Srivastava, Junzhou Huang, Hao Wang, Molei Tao, Vladimir Pavlovic, Dimitris Metaxas</h2>
    
    <!-- TL;DR Version -->
    <p class="abstract short-abstract">
        <hl>TL;DR:</hl> A framework for parameter-efficient fine-tuning by adjusting both singular values and their basis vectors, balancing computational efficiency and representation capacity.
        <span class="toggle-abstract show-full">(Show Full Abstract)</span>
    </p>

    <!-- Full Abstract (Initially Hidden) -->
    <p class="abstract full-abstract" style="display: none;">
      Adapting large-scale pre-trained generative models in a parameter-efficient manner
      is gaining traction. Traditional methods like low rank adaptation achieve parameter
      efficiency by imposing constraints but may not be optimal for tasks requiring
      high representation capacity. <hl>We propose a novel spectrum-aware adaptation
      framework for generative models. Our method adjusts both singular values and
      their basis vectors of pretrained weights.</hl> Using the Kronecker product and efficient
      Stiefel optimizers, we achieve parameter-efficient adaptation of orthogonal matrices.
      Specifically, we introduce Spectral Orthogonal Decomposition Adaptation (SODA),
      which balances computational efficiency and representation capacity. Extensive
      evaluations on text-to-image diffusion models demonstrate SODA’s effectiveness,
      offering a spectrum-aware alternative to existing fine-tuning methods.
        <span class="toggle-abstract show-tldr" style="display: none;">(Show TL;DR)</span>
    </p>

    <div class="pub-keywords">
        <span class="pub-keyword">Parameter Efficient Finetuning</span>
        <span class="pub-keyword">Diffusion Models</span>
        <span class="pub-keyword">WACV 2025</span>
    </div>
  </div>

  <!-- *********************************** -->
  <!-- **** Publication 3 TrajDiffuse **** -->
  <!-- *********************************** -->
  <div class="pub-container">
    <img src="data/images/pubs/trajDiffuse.jpg" alt="Sample Image" class="pub-image" width="200">
    
    <h1>
        <a href="https://arxiv.org/pdf/2410.10804" target="_blank" rel="noopener noreferrer">
          TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction
        </a>
    </h1>
    
    <h2>Qingze Tony Liu*, Danrui Li, Samuel S Sohn, Sejong Yoon, Mubbasir Kapadia, Vladimir Pavlovic </h2>
    
    <!-- TL;DR Version -->
    <p class="abstract short-abstract">
        <hl>TL;DR:</hl> Environment aware human trajectory prediction with guided conditional diffusion model.
        <span class="toggle-abstract show-full">(Show Full Abstract)</span>
    </p>

    <!-- Full Abstract (Initially Hidden) -->
    <p class="abstract full-abstract" style="display: none;">
      Accurate prediction of human or vehicle trajectories with
      good diversity that captures their stochastic nature is an essential task
      for many applications. However, many trajectory prediction models produce unreasonable trajectory samples that focus on improving diversity
      or accuracy while neglecting other key requirements, such as collision
      avoidance with the surrounding environment. In this work, we propose
      TrajDiffuse, a planning-based trajectory prediction method using a
      novel guided conditional diffusion model. We form the trajectory prediction problem as a denoising impaint task and design a map-based
      guidance term for the diffusion process. TrajDiffuse is able to generate
      trajectory predictions that match or exceed the accuracy and diversity of
      the SOTA, while adhering almost perfectly to environmental constraints.
      We demonstrate the utility of our model through experiments on the
      nuScenes and PFSD datasets and provide an extensive benchmark analysis against the SOTA methods.
        <span class="toggle-abstract show-tldr" style="display: none;">(Show TL;DR)</span>
    </p>

    <div class="pub-keywords">
        <span class="pub-keyword">Human Trajectory Prediction</span>
        <span class="pub-keyword">Diffusion Models</span>
        <span class="pub-keyword">ICPR 2025</span>
    </div>
    </div>
  

</body>
</html>